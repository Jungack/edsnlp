{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea703b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa9ccc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/tpetitjean/ecciMLConfit/.venv/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import Span\n",
    "from edsnlp.pipelines.misc.external_model import ModelWrapper\n",
    "\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1324ee",
   "metadata": {},
   "source": [
    "## 1. Defining a model\n",
    "\n",
    "This model can be anything (PyTorch, SKLearn, etc.).  \n",
    "Let's make an extremely basic sentiment analysis model.  \n",
    "\n",
    "You can use GPU if you want here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "185c1f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalysisModel:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def batching(\n",
    "        self,\n",
    "        data: Dict[str, List[Any]],\n",
    "        batch_size: int,\n",
    "    ):\n",
    "        i = 0\n",
    "        n = len(data[\"text\"])\n",
    "        while i < n:\n",
    "            yield {k: v[i : i + batch_size] for k, v in data.items()}\n",
    "            i += batch_size\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        batch,\n",
    "    ):\n",
    "        return [\n",
    "            {\n",
    "                \"good\": \"good\" in txt,\n",
    "                \"bad\": \"bad\" in txt,\n",
    "                \"neutral\": \"neutral\" in txt,\n",
    "                \"device\": 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "            }\n",
    "            for txt in batch[\"text\"]\n",
    "        ]\n",
    "    \n",
    "    def predict(\n",
    "        self,\n",
    "        data: Dict[str, List[Any]],\n",
    "        batch_size: int,\n",
    "    ):\n",
    "        preds = []\n",
    "        for batch in self.batching(data, batch_size):\n",
    "            preds += self.forward(batch)\n",
    "        return preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc34a65",
   "metadata": {},
   "source": [
    "We will test our model with some toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1c06f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_texts = [\n",
    "    \"It was a very good movie !\",\n",
    "    \"The cheese was pretty good.\",\n",
    "    \"It's gonna be a very good year, very good!\",\n",
    "]\n",
    "\n",
    "bad_texts = [\n",
    "    \"I have a bad feeling about this\",\n",
    "    \"This was pretty bad.\"\n",
    "]\n",
    "\n",
    "neutral = [\n",
    "    \"This is a neutral statement.\"\n",
    "]\n",
    "\n",
    "texts = 50*good_texts + 40*bad_texts + 30*neutral\n",
    "\n",
    "random.shuffle(texts)\n",
    "\n",
    "data = dict(text = texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3ef343ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentAnalysisModel()\n",
    "preds_from_model = model.predict(data, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "eaee46ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'good': True, 'bad': False, 'neutral': False, 'device': 'cpu'},\n",
       " 'The cheese was pretty good.')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_from_model[0], data[\"text\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df4592e",
   "metadata": {},
   "source": [
    "## 2. Wrap the model\n",
    "\n",
    "To use this model with EDS-NLP, you should wrap in by using the dedicated `ModelWrapper` class.  \n",
    "Two parameters are available here:\n",
    "- `span_getter`: To tell the wrapper how to generate inference data for your Model starting from a spaCy document\n",
    "- `annotation_setter`: From the output predictions of your model, how do you set them on the starting spaCy Doc, Span or Token.\n",
    "\n",
    "When creating your wrapper that inherits from `ModelWrapper`, you can either\n",
    "- Use a pre-registered function for those two parameters\n",
    "- Use your own by re-defining `self.span_getter` or `self.annotation_setter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "245d52b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SPAN_GETTER = {\n",
    "    \"@span_getters\": \"sentences\",\n",
    "}\n",
    "\n",
    "DEFAULT_ANNOTATION_SETTER = {\n",
    "    \"@annotation_setters\": \"from-mapping\",\n",
    "    \"mapping\": {\n",
    "        \"good\": \"_.good\",\n",
    "        \"bad\": \"_.bad\",\n",
    "        \"neutral\": \"_.neutral\",\n",
    "        \"device\": \"_.device\",\n",
    "    }\n",
    "}\n",
    "\n",
    "class SentimentAnalysisWrapper(ModelWrapper):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: SentimentAnalysisModel,\n",
    "        span_getter = DEFAULT_SPAN_GETTER,\n",
    "        annotation_setter = DEFAULT_ANNOTATION_SETTER,\n",
    "    ):\n",
    "        super().__init__(model, span_getter, annotation_setter)\n",
    "        \n",
    "    \n",
    "    def set_extensions(self):\n",
    "        for ext in [\"good\", \"bad\", \"neutral\", \"device\"]:\n",
    "            if not Span.has_extension(ext):\n",
    "                Span.set_extension(ext, default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b4a2b6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = SentimentAnalysisWrapper(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1990b382",
   "metadata": {},
   "source": [
    "Finally we will save this wrapper model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8fa67f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap.to_disk(\"./model.dill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf48aac",
   "metadata": {},
   "source": [
    "## 3. Use the wrapped model in a pipe\n",
    "\n",
    "Use the `eds.external-model` pipe and give the pickled model path in the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8ef42c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<edsnlp.pipelines.misc.external_model.external_model.ExternalModel at 0x7f82c0495510>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.blank(\"eds\")\n",
    "\n",
    "nlp.add_pipe(\"eds.sentences\")\n",
    "nlp.add_pipe(\"eds.external-model\", config=dict(model=\"./model.dill\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120ee262",
   "metadata": {},
   "source": [
    "Now simply use `nlp.pipe`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6965d534",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_preds = list(nlp.pipe(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4529829d",
   "metadata": {},
   "source": [
    "## 4. Sanity check\n",
    "\n",
    "Let us check that the ouput if the model and the output of `nlp.pipe` matches up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "55d186e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_preds = [\n",
    "    dict(\n",
    "        good = doc[0].sent._.good,\n",
    "        bad = doc[0].sent._.bad,\n",
    "        neutral = doc[0].sent._.neutral,\n",
    "        device = doc[0].sent._.device,\n",
    "    ) for doc in spacy_preds\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e83f8f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert preds_from_model == spacy_preds"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "382c60e41ce00a190f65d8f45615d14db0ccd1b0d25cbfcd143362faf11902d6"
  },
  "kernelspec": {
   "display_name": "edsml",
   "language": "python",
   "name": "edsml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
